# =============================================================================
# API KEYS
# =============================================================================
OPENAI_API_KEY=sk-your-openai-api-key-here
ELEVENLABS_API_KEY=your-elevenlabs-api-key-here

# =============================================================================
# UNREAL ENGINE INTEGRATION
# =============================================================================
# WebSocket endpoint for control messages (start/stop speaking, animations)
UNREAL_WEBSOCKET_URI=ws://localhost:8765

# UDP endpoint for Audio2Face audio streaming
# Audio2Face is running on a different machine at 192.168.1.14
UNREAL_AUDIO_UDP_HOST=192.168.1.14
UNREAL_AUDIO_UDP_PORT=8080

# =============================================================================
# NDI CONFIGURATION
# =============================================================================
# NDI source name (visible in NDI discovery)
NDI_SOURCE_NAME=MY_SOURCE

# Video processing settings
NDI_VIDEO_ENABLED=true
NDI_VIDEO_FPS=1  # Frame decimation: 1 fps to reduce CPU load
NDI_VIDEO_WIDTH=640
NDI_VIDEO_HEIGHT=360

# =============================================================================
# AUDIO SETTINGS
# =============================================================================
# Sample rate for Audio2Face (must be 24000 Hz)
AUDIO_SAMPLE_RATE=24000
AUDIO_CHANNELS=1

# =============================================================================
# LLM CONFIGURATION
# =============================================================================
LLM_PROVIDER=openai  # or anthropic
LLM_MODEL=gpt-4o
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=150

# System prompt
LLM_SYSTEM_PROMPT=You are a helpful AI assistant controlling a MetaHuman avatar. Keep responses concise and natural for voice conversation.

# =============================================================================
# TTS CONFIGURATION (ElevenLabs)
# =============================================================================
ELEVENLABS_VOICE_ID=your-voice-id-here
ELEVENLABS_MODEL=eleven_flash_v2_5  # Low latency model
ELEVENLABS_STABILITY=0.5
ELEVENLABS_SIMILARITY_BOOST=0.75
ELEVENLABS_OPTIMIZE_LATENCY=4  # Max optimization

# =============================================================================
# TRANSPORT CONFIGURATION
# =============================================================================
# WebRTC transport for user communication
TRANSPORT_TYPE=daily  # or small-webrtc
DAILY_ROOM_URL=https://your-daily-room.daily.co/room-name
DAILY_API_KEY=your-daily-api-key

# =============================================================================
# INTERRUPTION HANDLING
# =============================================================================
# Minimum words required for user to interrupt bot
INTERRUPTION_MIN_WORDS=3

# VAD (Voice Activity Detection) sensitivity
VAD_STOP_SECS=0.5  # Silence duration before considering user stopped speaking

# =============================================================================
# LOGGING
# =============================================================================
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
LOG_FORMAT=json  # or text
LOG_FILE=logs/avatar.log

# =============================================================================
# DEVELOPMENT
# =============================================================================
# Enable debug features
DEBUG=false

# Mock mode (for testing without Unreal)
MOCK_UNREAL=false

# =============================================================================
# FEATURE TOGGLES
# =============================================================================
# Disable these to test core Pipecat without Unreal Engine
ENABLE_UNREAL=true   # Set to false to disable WebSocket + UDP audio
ENABLE_NDI=true      # Set to false to disable NDI video/audio
