# CLAUDE.md - Documentation D√©veloppeur IA

## üìã Vue d'ensemble du Projet

**Avatar MetaHuman Pipeline** - Syst√®me conversationnel IA temps r√©el pour contr√¥ler un MetaHuman dans Unreal Engine via Audio2Face, utilisant Pipecat 0.95.

### Objectif
Migrer un script PyQt5 legacy vers une architecture moderne bas√©e sur Pipecat pour :
- Streaming audio/vid√©o NDI
- Synchronisation labiale parfaite (Audio2Face)
- Contr√¥le √©motionnel via LLM (Function Calling)
- Latence sub-seconde (<500ms)
- Support barge-in (interruption gracieuse)

---

## üèóÔ∏è Architecture du Syst√®me

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    INPUT LAYER (NDI)                            ‚îÇ
‚îÇ  GStreamer ‚Üí NDIInputTransport ‚Üí InputImageRawFrame            ‚îÇ
‚îÇ              (1 fps decimation)   InputAudioRawFrame           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 COGNITIVE LAYER (LLM)                           ‚îÇ
‚îÇ  STT ‚Üí ContextAggregator ‚Üí OpenAI/Anthropic LLM                ‚îÇ
‚îÇ                             (Function Calling: animate_avatar)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              SYNTHESIS LAYER (TTS)                              ‚îÇ
‚îÇ  ElevenLabs WebSocket TTS (eleven_flash_v2_5, 24kHz)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           OUTPUT LAYER (ParallelPipeline)                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ Branch A: User       ‚îÇ  ‚îÇ Branch B: Unreal MetaHuman       ‚îÇ‚îÇ
‚îÇ  ‚îÇ WebRTC Transport     ‚îÇ  ‚îÇ UnrealEventProcessor (WebSocket) ‚îÇ‚îÇ
‚îÇ  ‚îÇ (User hears voice)   ‚îÇ  ‚îÇ UnrealAudioStreamer (UDP 8080)   ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÇ Structure du Projet

```
avatar/
‚îú‚îÄ‚îÄ src/avatar/
‚îÇ   ‚îú‚îÄ‚îÄ processors/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unreal_event_processor.py    # WebSocket control (start/stop speaking)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unreal_audio_streamer.py     # UDP audio streaming (24kHz ‚Üí A2F)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ndi_input_transport.py       # GStreamer NDI ‚Üí Pipecat frames
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main_pipeline.py             # ParallelPipeline assembly
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ settings.py                  # Configuration centralis√©e
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_unreal_event_processor.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_unreal_audio_streamer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_ndi_input_transport.py
‚îÇ   ‚îî‚îÄ‚îÄ integration/
‚îÇ       ‚îú‚îÄ‚îÄ test_pipeline.py
‚îÇ       ‚îî‚îÄ‚îÄ test_mock_unreal.py
‚îú‚îÄ‚îÄ claude_dev/                          # Scripts de d√©veloppement pour Claude
‚îÇ   ‚îú‚îÄ‚îÄ test_websocket.py
‚îÇ   ‚îú‚îÄ‚îÄ test_udp_sender.py
‚îÇ   ‚îî‚îÄ‚îÄ mock_unreal_server.py
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îî‚îÄ‚îÄ simple_demo.py
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ CLAUDE.md                        # Ce fichier
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md
‚îÇ   ‚îî‚îÄ‚îÄ API.md
‚îú‚îÄ‚îÄ pyproject.toml                       # UV + Poetry compatible
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

---

## üîë Composants Cl√©s

### 1. UnrealEventProcessor
**R√¥le:** √âcoute `TTSStartedFrame` / `TTSStoppedFrame` et envoie WebSocket events √† Unreal.

**Frames g√©r√©s:**
- `TTSStartedFrame` ‚Üí `{"type": "start_speaking", "category": "SPEAKING_NEUTRAL"}`
- `TTSStoppedFrame` ‚Üí `{"type": "stop_speaking"}`
- `StartInterruptionFrame` ‚Üí `{"type": "stop_speaking"}` (barge-in)

**WebSocket URI:** `ws://localhost:8765`

### 2. UnrealAudioStreamer
**R√¥le:** Envoie audio brut via UDP vers Audio2Face.

**Specs:**
- Sample rate: **24kHz** (requis par Audio2Face)
- Format: PCM raw bytes
- Transport: UDP non-blocking (`socket.SOCK_DGRAM`)
- Target: `127.0.0.1:8080`

**Frames g√©r√©s:**
- `OutputAudioRawFrame` ‚Üí UDP packet

### 3. NDIInputTransport
**R√¥le:** Ingestion NDI via GStreamer ‚Üí Pipecat frames.

**GStreamer Pipeline:**
```bash
ndisrc ndi-name="MY_SOURCE" ! \
  videoconvert ! video/x-raw,format=RGB ! \
  videorate ! video/x-raw,framerate=1/1 ! \
  appsink name=sink
```

**Frame Decimation:** 1 fps (√©vite surcharge CPU/GIL)

### 4. ParallelPipeline
**R√¥le:** Fork audio TTS vers 2 destinations simultan√©es.

**Impl√©mentation:**
```python
ParallelPipeline(
    [transport.output()],           # Branch A: User WebRTC
    [
        UnrealEventProcessor(),     # Branch B: Unreal control
        SoxrResampler(24000),       # Resample to 24kHz
        UnrealAudioStreamer()       # UDP to Audio2Face
    ]
)
```

---

## üß™ Tests et Validation

### Structure de Tests

#### Unit Tests (`tests/unit/`)
- **test_unreal_event_processor.py:**
  - V√©rifie emission WebSocket sur `TTSStartedFrame`
  - V√©rifie reconnexion automatique
  - Mock `websockets.connect()`

- **test_unreal_audio_streamer.py:**
  - V√©rifie envoi UDP sur `OutputAudioRawFrame`
  - V√©rifie gestion `BlockingIOError`
  - Mock `socket.sendto()`

- **test_ndi_input_transport.py:**
  - V√©rifie parsing GStreamer buffer
  - V√©rifie cr√©ation `InputImageRawFrame`
  - Mock GStreamer pipeline

#### Integration Tests (`tests/integration/`)
- **test_pipeline.py:**
  - Test pipeline complet end-to-end
  - V√©rifie synchronisation branches parall√®les

- **test_mock_unreal.py:**
  - Serveur WebSocket mock pour simuler Unreal
  - V√©rifie r√©ception des commands

### Scripts de D√©veloppement (`claude_dev/`)

#### mock_unreal_server.py
```python
# Serveur WebSocket qui simule Unreal Engine
# Usage: python claude_dev/mock_unreal_server.py
# √âcoute sur ws://localhost:8765
# Affiche tous les messages re√ßus
```

#### test_udp_sender.py
```python
# Envoie un fichier WAV via UDP vers Audio2Face
# Usage: python claude_dev/test_udp_sender.py audio.wav
# Permet de tester l'int√©gration Audio2Face ind√©pendamment
```

---

## ‚öôÔ∏è Configuration

### Variables d'Environnement (.env)

```bash
# API Keys
OPENAI_API_KEY=sk-...
ELEVENLABS_API_KEY=...

# Unreal Integration
UNREAL_WEBSOCKET_URI=ws://localhost:8765
UNREAL_AUDIO_UDP_HOST=127.0.0.1
UNREAL_AUDIO_UDP_PORT=8080

# NDI
NDI_SOURCE_NAME=MY_SOURCE

# Audio Settings
AUDIO_SAMPLE_RATE=24000
AUDIO_CHANNELS=1

# LLM Settings
LLM_MODEL=gpt-4o
LLM_TEMPERATURE=0.7

# TTS Settings
ELEVENLABS_VOICE_ID=...
ELEVENLABS_MODEL=eleven_flash_v2_5
```

---

## üõ†Ô∏è Outils de Qualit√© de Code

### 1. Black - Formatage
```bash
poetry run black src/ tests/
```
Config: 100 caract√®res, Python 3.10+

### 2. Ruff - Linting
```bash
poetry run ruff check src/ tests/ --fix
```
R√®gles: E, W, F, I, C, B, UP

### 3. MyPy - Type Checking
```bash
poetry run mypy src/
```
Strict mode activ√©

### 4. Pytest - Tests avec Couverture
```bash
poetry run pytest --cov
poetry run pytest tests/unit -v
poetry run pytest -m "not slow"
```

### 5. Pre-commit Hooks
```bash
poetry run pre-commit run --all-files
```

---

## üöÄ Workflow de D√©veloppement

### Ajout d'une Nouvelle Feature

1. **Cr√©er une branche:**
   ```bash
   git checkout -b feature/nouvelle-feature
   ```

2. **D√©velopper avec tests:**
   ```bash
   # √âcrire le code dans src/
   # √âcrire les tests dans tests/unit/
   ```

3. **Valider la qualit√©:**
   ```bash
   poetry run black src/ tests/
   poetry run ruff check src/ tests/ --fix
   poetry run mypy src/
   poetry run pytest
   ```

4. **Commit et push:**
   ```bash
   git add .
   git commit -m "feat: description"
   git push origin feature/nouvelle-feature
   ```

### R√©solution de Bugs

1. **√âcrire un test qui reproduit le bug** (test_bug.py)
2. **Corriger le code**
3. **V√©rifier que le test passe**
4. **Valider avec pre-commit**

---

## üìä M√©triques de Performance

### Objectifs de Latence

| √âtape | Cible | Mesure |
|-------|-------|--------|
| STT (user ‚Üí text) | <200ms | `time(UserStoppedSpeaking) - time(UserStartedSpeaking)` |
| LLM (text ‚Üí response) | <500ms | `time(LLMResponse) - time(STTComplete)` |
| TTS (text ‚Üí audio) | <250ms | `time(FirstAudioChunk) - time(TTSStart)` |
| **Total (user ‚Üí avatar)** | **<1000ms** | End-to-end measurement |

### Monitoring

```python
# Dans le pipeline, utiliser des Observers
from pipecat.observers.base_observer import BaseObserver

class LatencyObserver(BaseObserver):
    async def on_push_frame(self, src, dst, frame, direction, timestamp):
        # Log timestamps pour analyse
        logger.debug(f"{timestamp}: {type(frame).__name__}")
```

---

## üîê S√©curit√©

### API Keys
- **Jamais** commit `.env` dans Git
- Utiliser `.env.example` comme template
- Rotation r√©guli√®re des cl√©s

### WebSocket
- En production, utiliser `wss://` (TLS)
- Authentification par token si expos√©

### UDP
- Audio2Face local uniquement (pas d'exposition publique)
- Firewall: bloquer port 8080 en ingress

---

## üêõ Debugging

### Probl√®mes Courants

#### 1. Avatar ne bouge pas les l√®vres
**Causes possibles:**
- Audio UDP non re√ßu ‚Üí V√©rifier `netstat -an | grep 8080`
- Sample rate incorrect ‚Üí Doit √™tre 24kHz
- WebSocket non connect√© ‚Üí V√©rifier logs `UnrealEventProcessor`

**Debug:**
```bash
# Tester UDP directement
python claude_dev/test_udp_sender.py audio_24khz.wav

# Tester WebSocket
python claude_dev/mock_unreal_server.py
# Dans un autre terminal: tester avec wscat
```

#### 2. Audio d√©synchronis√©
**Cause:** Branches parall√®les pas au m√™me sample rate

**Fix:** V√©rifier `SoxrResampler(24000)` dans Branch B

#### 3. Latence √©lev√©e
**Causes:**
- NDI √† 30fps au lieu de 1fps ‚Üí CPU/GIL satur√©
- ElevenLabs HTTP au lieu de WebSocket ‚Üí Utiliser `ElevenLabsTTSService`
- Pas de `MinWordsInterruptionStrategy` ‚Üí Faux positifs VAD

---

## üìö Ressources

### Documentation Pipecat
- [Pipecat Docs](https://docs.pipecat.ai)
- [API Reference](https://reference-server.pipecat.ai)
- [GitHub](https://github.com/pipecat-ai/pipecat)

### Documentation Technique
- [Audio2Face](https://docs.omniverse.nvidia.com/audio2face)
- [NDI SDK](https://ndi.tv/sdk/)
- [GStreamer NDI Plugin](https://github.com/teltek/gst-plugin-ndi)

### Audit Original
Voir `/home/gieidi-prime/Agents/Avatar/audit.md` pour analyse d√©taill√©e du legacy code.

---

## üéØ Prochaines √âtapes (Roadmap)

- [ ] **Phase 1: Core Processors** (Semaine 1)
  - UnrealEventProcessor
  - UnrealAudioStreamer
  - Tests unitaires

- [ ] **Phase 2: NDI Integration** (Semaine 2)
  - NDIInputTransport
  - GStreamer pipeline
  - Tests int√©gration

- [ ] **Phase 3: Pipeline Assembly** (Semaine 3)
  - ParallelPipeline
  - ElevenLabs TTS
  - LLM Function Calling

- [ ] **Phase 4: Polish** (Semaine 4)
  - Monitoring
  - Documentation
  - CI/CD

---

**Derni√®re mise √† jour:** 2025-11-19
**Mainteneur:** Claude (Anthropic)
**Statut:** üöß En D√©veloppement
